+++
Sources = [
"https://github.com/torvalds/linux/commit/4494dd58fbb477e54c129c1d8ef477aad433eba0",
"https://mirrors.edge.kernel.org/pub/linux/kernel/people/paulmck/LWNLinuxMM/StrongModel.html",
"https://github.com/paulmckrcu/oota",
"https://lwn.net/Articles/720550/",
"https://diy.inria.fr/linux/long.pdf",
"https://github.com/torvalds/linux/blob/master/tools/memory-model/Documentation/explanation.txt",
"https://github.com/paulmckrcu/perfbook",

]
authors = [
"Michael Shalitin",

]
math = true
date = "2025-01-11"
categories = [

]
series = [

]
title = "LKMM"
+++







???



- [x] [לתרגם את simple.txt](file:///Users/michael/Desktop/1/%D7%AA%D7%9B%D7%A0%D7%95%D7%AA/kernel/files/txt_files_(not_coplite)/simple.txt)

- [ ] לבדוק את [lock.cat](https://github.com/torvalds/linux/blob/master/tools/memory-model/lock.cat) ???
- [ ] לבדוק את [perfbook](file:///Users/michael/Desktop/1/%D7%AA%D7%9B%D7%A0%D7%95%D7%AA/kernel/files/perfbook-1c.2023.06.11a.pdf)
- [ ] לבדוק את [הפוקנציות של herd](https://diy.inria.fr/doc/herd.html#sec%3Acos)

## לתרגם
- [x] [Linux-Kernel Memory Model 2023](https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2023/p0124r8.html) לבדוק (+לתרגם)
- [x] [locking.txt](https://github.com/torvalds/linux/blob/master/tools/memory-model/Documentation/locking.txt) ? לתרגם ולבדוק
- [x] לתרגם ולבדוק את [spinlocks.txt](https://www.kernel.org/doc/Documentation/locking/spinlocks.txt)
- [ ] לתרגם את [perfbook](file:///Users/michael/Desktop/1/%D7%AA%D7%9B%D7%A0%D7%95%D7%AA/kernel/files/perfbook-1c.2023.06.11a.pdf)


- [ ] לבדוק אם כדאי להכניס קטעים מ-[locking.txt](https://github.com/torvalds/linux/blob/master/tools/memory-model/Documentation/locking.txt) למאמר

- [ ] לחזור על הדוגמאות קוד [במאמר Lockless patterns: full memory barriers](https://lwn.net/Articles/847481/)  


- [ ] בהסבר בקבצי cat של הקרנל לתת הסבר לסיבה למה הדברים מוגדרים ככה (לתת הסבר למה לא רק מה)


---
- [ ] להוסיף סוגרים מסולסלים גדולים לחלקים שצריכים כמו [בסיכום של Scheduling](https://smichaelshal.github.io)

# קבצי המודל

## מילון
`LKR` - Lock-Read
`LKW` - Lock-Write
`UL` - Unlock
`LF` - Lock-Fail
`RL` - Read-Locked
`RU` - Read-Unlocked
`ilb` - idle load balancer
## הקובץ `linux-kernel.bell`

בקובץ `tools/memory-model/linux-kernel.bell` מוגדרים מספר הגדרות מעניינות:

### תיוג אירועים

```ocaml {linenos=inline}
enum Accesses = 'once (*READ_ONCE,WRITE_ONCE*) ||
		'release (*smp_store_release*) ||
		'acquire (*smp_load_acquire*) ||
		'noreturn (* R of non-return RMW *)
instructions R[{'once,'acquire,'noreturn}]
instructions W[{'once,'release}]
instructions RMW[{'once,'acquire,'release}]

enum Barriers = 'wmb (*smp_wmb*) ||
		'rmb (*smp_rmb*) ||
		'mb (*smp_mb*) ||
		'barrier (*barrier*) ||
		'rcu-lock (*rcu_read_lock*)  ||
		'rcu-unlock (*rcu_read_unlock*) ||
		'sync-rcu (*synchronize_rcu*) ||
		'before-atomic (*smp_mb__before_atomic*) ||
		'after-atomic (*smp_mb__after_atomic*) ||
		'after-spinlock (*smp_mb__after_spinlock*) ||
		'after-unlock-lock (*smp_mb__after_unlock_lock*) ||
		'after-srcu-read-unlock (*smp_mb__after_srcu_read_unlock*)
instructions F[Barriers]
```

כאן מגדירים תגים לאירועים (האירועים מוגדרים ומתויגים ב-`tools/memory-model/linux-kernel.def`).


### גישות פשוטות ומסומנות

```ocaml {linenos=inline}
(* Compute marked and plain memory accesses *)

let Marked = (~M) | IW | Once | Release | Acquire | domain(rmw) | range(rmw) | LKR | LKW | UL | LF | RL | RU | Srcu-lock | Srcu-unlock

let Plain = M \ Marked
```

#### הקבוצה `Marked`
הקבוצה מכילה את הגישה המסומנת (כלומר גישה מיוחדת) לזיכרון.
##### הסבר לכתיב הפורמלי:

השפה cat מספקת למשתמש קבוצות מוגדרות מראש של אירועים, כמו האירוע `M` שהוא מכיל את כל הכתיבות והקריאות.

הכתיבה הראשונית למשתנה מסיום שנעשית לפני התחלת התוכנית מסומנת על ידי `IW`.

ה-domain מחזיר את הקלטים של היחסים (כלומר את הצד השמאלי של הזוג ביחס).
ה-range מחזיר את הפלטים של היחסים (כלומר את הצד הימני של הזוג ביחס).

ההגדרה של `Marked` אומרת שהיא מכילה את כל:

- האירועים שהם: לא גישות של קריאה וכתיבה - `(~M)`
- הכתיבות הראשוניות-  `IW`
- אירועים שמסומנים עם אחת מהאנוטציות: `Once` ,`Release` ,`Acquire`
- אירועים של פעולות rmw (האיבר הראשון (domain) והאחרון (range)) - `domain(rmw) | range(rmw)`
- אירועי נעילה `LKR`, `LKW`, `UL`, `RL`, `RU`, `Srcu-lock`, `Srcu-unlock`

#### הקבוצה `Plain`
הקבוצה מכילה את הגישות הרגילות לזיכרון.

##### הסבר לכתיב הפורמלי:
כל הגישות לזיכרון (`M`) מלבד אלה שנמצאים בקבוצה `Marked`.


##### הגדרה מחדש של התלויות

```
(* Redefine dependencies to include those carried through plain accesses *)

let carry-dep = (data ; [~ Srcu-unlock] ; rfi)*
let addr = carry-dep ; addr
let ctrl = carry-dep ; ctrl
let data = carry-dep ; data
```


כאן יש הגדרה מחדש של יחסי התלות שכוללת העברה של תלות נתונים גם על ידי גישות רגילות  (`[~ Srcu-unlock]`).
ה-`carry-dep` מכיל תלות נתונים ואחריו כל אירוע שהוא לא מסוג `Srcu-unlock` אבל הוא חייב להיות בעל סיומת של כתיבה בגלל החלק הבא של ההגדרה של `carry-dep` שמחייב שיהיה `rfi`.
ההגדרה החדשה של התלויות מכילה רצף בכל אורך של `carry-dep` (בגלל הסיומת של `*`) ואחריו יש יחס תלות בהתאמה.


## הקובץ `linux-kernel.cat`
    

### Basic relations

#### Release Acquire

```ocaml {linenos=inline}
(* Release Acquire *)
let acq-po = [Acquire] ; po ; [M]
let po-rel = [M] ; po ; [Release]

let po-unlock-lock-po = po ; [UL] ; (po|rf) ; [LKR] ; po
```



היחס`acq-po` מקשר כל פעולת acquire לכל גישה אחרת לזיכרון שמגיעה בסדר התוכנית אחרי פעולת ה-acquire. זה מוגדר על ידי היחס po שמגבילים את ה-domain (האיבר השמאלי) להיות מסוג `Acquire` ומגבילים את ה-range (האיבר הימני) להיות קריאה או כתיבה (`M`).

היחס`po-rel` מקשר כל גישה לזיכרון לפעולת release שמגיעה בסדר התוכנית אחרי לפני ה-release. ההגדרה של היחס דומה ל-`acq-po` רק יש היפוך בסדר ושימוש בתג `Release`.

היחס `po-unlock-lock-po` מקשר בין אירוע בסדר התוכנית (`po`) שהוא שחרור נעילה (`UL`) של `spin_unlock` ואחריו יכול להגיע: אחד מהאפשרויות הבאות:
- כל אירוע בסדר התוכנית (`po`)
- אירוע שקורא מתוך הכתיבה (`rf`) בשחרור הנעילה (`UL`) 

אחרי אחת מהאפשרויות האלו יש אירוע של חלק הקריאה של `spin_lock()` או `spin_trylock()` מוצלח של זוג אירוע rmw (נכתב כ-`LKR`).

הרעיון כאן הוא שהרצף של שחרור נעילה ולאחר מכן נעילה מוצלחת צריכים להיות מסודרים ב-2 מקרים:
- אם ה-lock וגם ה-unlock נעשים על אותו מנעול אז ברור שצריך ביניהם סדר כי זה הבסיס לנעילה, שהנעילה צריכה לקרות לאחר שהיא קראה את השחרור הנעילה הקודמת.
- אם ה-lock וגם ה-unlock נעשים על אותו מעבד, כלומר זה מבטיח שגם אם משתמשים במנעולים שונים בין שתי הפעולות עדיין באותו מעבד האירועים צריכים לשמור על סדר וזה מופיע כאן בצורה הפורמלית על ידי ה-`po`.


#### Fences
 
```ocaml {linenos=inline}
let R4rmb = R \ Noreturn (* Reads for which rmb works *)
let rmb = [R4rmb] ; fencerel(Rmb) ; [R4rmb]
let wmb = [W] ; fencerel(Wmb) ; [W]

let mb = ([M] ; fencerel(Mb) ; [M]) |
	([M] ; fencerel(Before-atomic) ; [RMW] ; po? ; [M]) |
	([M] ; po? ; [RMW] ; fencerel(After-atomic) ; [M]) |
	([M] ; po? ; [LKW] ; fencerel(After-spinlock) ; [M]) |
	([M] ; po-unlock-lock-po ;
		[After-unlock-lock] ; po ; [M]) |
	([M] ; po? ; [Srcu-unlock] ;
		fencerel(After-srcu-read-unlock) ; [M])
```


היחס`R4rmb` מכיל את פעולות הקריאה שמחזירות ערך. ה-`R4rmb`: היא מחלקת הקריאות שעליה יחול rmb.
היחס מוגדר על ידי כל אירועי הקריאה (`R`) מלבד (האופרטור `\`) האירועים שלא מחזירים ערך (`Noreturn`).

היחס `rmb` מקשר פעולת קריאה שתפיסה ל-`rmb` (האירועים ב-`R4rmb`) לפעולת קריאה אחרת שתפיסה ל-`rmb` ובניהם יש מחסום זיכרון קריאה (`Rmb`).

היחס `wmb` מקשר כל פעולת כתיבה (`W`) לפעולת כתיבה אחרת ובניהם יש מחסום זיכרון כתיבה (`Wmb`).

היחס `mb` מציג מחסום זיכרון מלא, כלומר הוא צריך להכיל בתוכו מספר יחסים שהוא צריך לשמור על סדר ביניהם ולכן הוא כולל מספר סעיפים, אבל החלק שלרוב מעניין בהגדרה של `mb` היא לרוב השורה הראשונה כי שאר הסעיפים מתאימים להתנהגויות של פעולות אטומיות ומנעולים ספציפים.

בשורה הראשונה מוגדר קישור בין כל פעולת גישה לזיכרון (`M`) לפעולת גישה לזיכרון אחרת ובינהם יש מחסום זיכרון מלא (`Mb`).

שאר הסעיפים בהגדרה:

- מקשר בין כל פעולת גישה לזיכרון לאירוע `RMW` ובניהם יש מחסום `smp_mb__before_atomic` (בכתיב פורמלי - `Before-atomic`) ולאחר מכן  יכול להיות אירוע אחד או בכלל לא (`?`) בסדר התוכנית (`po`) שהוא מסוג גישה לזיכרון (`[M]`).

- מקשר בין אירוע גישה לזיכרון אחד או בכלל לא (`?`) בסדר התוכנית  (`po`) לאירוע `RMW` ולאחר ה-`RMW` יש אירוע מחסום זיכרון `smp_mb__after_atomic` (בכתיב פורמלי -`After-atomic`) ואחריו יש פעולת גישה לזיכרון (`[M]`).

- מקשר בין אירוע גישה לזיכרון אחד או בכלל לא (`?`) בסדר התוכנית  (`po`) לאירוע של חלק הכתיבה של נעילה (`LKW`) ולאחריו יש אירוע מחסום זיכרון `smp_mb__after_spinlock` (בכתיב פורמלי -`After-spinlock`) ואחריו יש פעולת גישה לזיכרון (`[M]`).

- מקשר בין אירוע גישה לזיכרון ואחריו מתקיים קשר של `po-unlock-lock-po` שנגמר ב- `smp_mb__after_unlock_lock` (בכתיב פורמלי - `After-unlock-lock`)  ואחריו יש בסדר התוכנית (`po`) גישה לזיכרון (`M`).

- מקשר בין אירוע גישה לזיכרון אחד או בכלל לא (`?`) בסדר התוכנית  (`po`) ואחריו מגיע אירוע מסוג `Srcu-unlock` ואחריו יש קשר של מחסום `After-srcu-read-unlock` שמסתיים באירוע גישה לזיכרון (`M`).

```ocaml {linenos=inline}
let gp = po ; [Sync-rcu | Sync-srcu] ; po?
let strong-fence = mb | gp
```

בחלק הזה מוגדר היחס gp (ה-grace period של ה-rcu) שכדי להסביר את המהות שלו צריך להבין את rcu וזה כבר דורש מאמר נפרד, אבל אפשר כרגע להתייחס אליו כסוג של מחסום זיכרון חזק ל-rcu לצרוך ההגדרה של `strong-fence`.

היחס `strong-fence` מכיל את המחסום זיכרון המלא `mb` וה-`gp`.

```ocaml {linenos=inline}
let nonrw-fence = strong-fence | po-rel | acq-po
let fence = nonrw-fence | wmb | rmb
let barrier = fencerel(Barrier | Rmb | Wmb | Mb | Sync-rcu |
	Sync-srcu | Before-atomic | After-atomic | Acquire |
	Release | Rcu-lock | Rcu-unlock | Srcu-lock |Srcu-unlock)
	| (po ; [Release]) | ([Acquire] ; po)
```

היחס `nonrw-fence` מכיל את הקשרים של המחסומים שאין להם סמנטיקה של קריאה או כתיבה ולכן הוא מכיל את הקשרים של המחסומים החזקים ואת הקשרים של acquire ו-release.

היחס `fence` מכיל את הקשרים של המחסומים גם אלה עם הסמנטיקה של קריאה או כתיבה וגם אלה ללא הסמנטיקה.

היחס`barrier` מכיל את כל הקשרים של המחסומים.

### Fundamental coherence ordering
 

#### Sequential Consistency Per Variable




```ocaml {linenos=inline}
let com = rf | co | fr
acyclic po-loc | com as coherence
```


המודל מגדיר את קוהרנטיות cache באמצעות יחס `com` (קיצור של communicate). תהליך בדיקת הקוהרנטיות מתבצע על ידי בחינת האיחוד של יחסי `po-loc` ו-`com`, תוך הקפדה על כך שלא יווצרו מחזורים בלתי רצויים.

#### Atomic Read-Modify-Write





```ocaml {linenos=inline}
(* Atomic Read-Modify-Write *)
empty rmw & (fre ; coe) as atomic
```
מה שהופך פעולות RMW לאטומיות הוא שאף כתיבה ממעבד אחר לא רשאית להתערב (בסדר הקוהרנטיות) בין הכתיבה שממנה פעולת RMW קוראת לבין הכתיבה של ה-RMW עצמו.

הקשר `rmw` מחבר בין קריאה וכתיבה במסגרת אותה פעולה אטומית. כלומר, הוא מחבר בין הקריאה שמבוצעת על ידי פעולת RMW לבין הכתיבה של אותה פעולה.

פעולת RMW מבטיחה שבקריאה ובכתיבה המתרחשות בה תהיה תלות ישירה, כך שלא יופיעו התערבויות חיצוניות בין שני שלבי הפעולה.

הביטוי `fre ; coe` מגדיר קשר בין קריאה לכתיבה מאוחרת יותר של אותו משתנה. שהקריאה מספקת ערך מסוים שנכתב על ידי פעולה קודמת, והכתיבה המאוחרת יותר מתבצעת על ידי thread כלשהו. מצב זה מתרחש כאשר לפחות פעולה אחת של כתיבה מתערבת התבצעה.

ב-LKMM, הקשר `rmw` מחבר את אירועי הקריאה והכתיבה המרכיבים כל עדכון אטומי. זהו חלק מהאקסיומה של אטומיות במודל ה-LKMM, אשר מבטיחה את הקוהרנטיות של הפעולה האטומית.

במקרה שבו הקריאה היא חלק מפעולת RMW, והכתיבה הסופית היא הכתיבה של אותה פעולת RMW, התערבות מצד כתיבה של thread אחר מפרה את עקרון האטומיות. הפרה זו מתרחשת כאשר הכתיבה של ה-thread האחר מופיעה לאחר הקריאה של ה-RMW, אך לפני הכתיבה שלה, מה שגורם לכך שהפעולה כולה מאבדת את ההבטחה האטומית שלה.

השורה האחרונה מציבה תנאי למניעת הפרות כאלה שנקרא `atomic`: התנאי דורש שהחיתוך של `rmw` עם `fre ; coe` יהיה ריק. במילים אחרות, אסור לאפשר מצב שבו פעולה אטומית מסוג RMW תופר על ידי התערבות של כתיבה חיצונית בין הקריאה לכתיבה שהיא מבצעת.

בניסוח יותר פורמלי:

$$
\begin{aligned}
R_{a} - \textrm{atomic read} \\
W_{a} - \textrm{atomic write} \\
\\
R_{a} \to_{\textrm{fre}} W_{1}  \ ; \ W_{1} \to_{\textrm{coe}} W_{a} \\
\Downarrow \\
R_{a} \to W_{a} \\
\\
\textrm{rmw} \ \cap \ R_{a} \to W_{a}
\end{aligned}
$$

החיתוך בין ה-rmw לפעולת הקריאה והכתיבה צריך להיות ריק בגלל שהוא קיים רק כשיש פעולה -$W_{1}$ שמתרחשת בין -$R_{a}$ ל-$W_{a}$ (הוא קיים עם אופרטור הרצף בבדיקה כאן).

אפשר לנסחת זה ככה: $R \to_{\textrm{rmw}} W$  וזה אומר שכש- `W'` הוא כתיבה לפני `W` אז **לא קורה** ש-`R` קורא מתוך הכתיבה `W'`. ולכן הביטוי הזה יוצר קבוצה ריקה:

$$

\begin{aligned}
R \to_{\textrm{fr}} W' \ \wedge W' \ \to_{\textrm{co}} W
\end{aligned}
$$

### Instruction execution ordering

#### Preserved Program Order

```ocaml {linenos=inline}
let dep = addr | data
let rwdep = (dep | ctrl) ; [W]
let overwrite = co | fr
let to-w = rwdep | (overwrite & int) | (addr ; [Plain] ; wmb)
let to-r = (addr ; [R]) | (dep ; [Marked] ; rfi)
let ppo = to-r | to-w | (fence & int) | (po-unlock-lock-po & int)
```

##### תלויות
###### תלויות לכתיבה
תלות יכולה גם לגרום לביצוע הוראות לפי סדר התוכנית. זה לא שנוי במחלוקת כאשר ההוראה השנייה היא store וגם יש תלות data, addr או ctrl מהקריאה R לכתיבה W, זה יאלץ את המעבד לבצע את R לפני W.

במקרה של תלות addr בין 2 loads ה-range חייב להיות `READ_ONCE` או גישה אטומית, אחרת הסדר לא נשמר.

המעבד אינו מסוגל להודיע לתת-מערכת הזיכרון על ביצוע כתיבה עד אשר מתקיימים תנאים מסוימים שמאפשרים את ביצועה:

- **תלות data:** המעבד חייב לדעת מהו הערך הספציפי שצריך להיכתב לזיכרון.

- **תלות ctrl:** המעבד צריך לוודא שהכתיבה צריכה להתבצע בפועל.

- **תלות addr:** המעבד צריך לדעת את המיקום המדויק בזיכרון שבו יש לבצע את הכתיבה.

###### תלויות לקריאה

התלות בהוראות loads מציבה אתגרים מורכבים יותר בהשוואה לתלות בהוראות stores.

- **תלות data:** בניגוד להוראות כתיבה, אין מושג של תלות נתונים בהוראות load. זאת משום שפעולת ה-load היא הוראה שאין לה פרמטר קלט ויש לה רק פלט (יש קלט של כתובת אבל זה כבר תלות שונה).

- **תלות ctrl:** המעבד אינו מחויב לכבד תלות בקרה כשמדובר ב-load. הסיבה לכך היא שהוא יכול לבצע את ה-load השני באופן ספקולטיבי, כלומר, עוד לפני שה-load הראשון הושלם או אפילו אושר כדרוש. אם מאוחר יותר מתברר שה-load השני לא היה אמור להתבצע, המעבד פשוט מתעלם מתוצאתו ומשליך אותה, בלי להשפיע על המערכת.

- **תלות addr:** בכל הארכיטקטורות הנתמכות על ידי לינוקס, כאשר קיימת תלות בכתובת בין הוראות loads, המעבד מבצע את הטעינות לפי סדר התוכנית. כאשר כתובת ה-load השני תלויה בתוצאת ה-load הראשון, המעבד אינו מסוגל לשלוח בקשה לתת-מערכת הזיכרון לטעון ערך מהמיקום של ה-load השני לפני שהוא מחשב את הכתובת ממנה יש לטעון.


##### 


היחס `dep` מכיל את היחסים של התלויות כתובת (`addr`) ונתונים (`data`).

היחס `rwdep` מכיל את שלושת התלויות (`ctrl`, `addr` ו-`data`) ומחייב שה-range ביחס (הצד הימני) יהיה כתיבה (`W`).

היחס `overwrite` כמו שהוא נקרא הוא מכיל את היחסים שדרסו מידע והחליפו את המידע הישן במידע חדש.

##### to-w

היחס `to-w` מקשר אירועים לכתיבה והוא יחסית פשוט כי הארכיטקטורות תומכות בו בצורה פשוטה יחסית כמו שהוסבר קודם. היחס הוא איחוד של `rwdep` ו-`overwrite` פנימי (`overwrite & int`) וגם תלות כתובת שמסתיימת בגישת זיכרון רגילה שאחריה יש מחסום `wmb` (נכתב `addr ; [Plain] ; wmb`).




##### to-r
הרעיון של היחס `to-r` הוא לקשר אירועים לקריאה והיחס מורכב מ-2 חלקים:

החלק הראשון הוא `addr ; [R]` והרעיון שלו כבר הוסבר שבלינוקס נשמר הסדר ביחס ה-`addr` וכאן בגלל שזה יחס לקריאה אז צריך שה-range יהיה אירוע קריאה.

החלק השני `dep ; [Marked] ; rfi` דורש הסבר קצר:

הקישור rfi מחבר בין כתיבה לקריאה באותו thread. הקריאה עשויה לקבל את ערכה ישירות מהכתיבה (על ידי forward) או באמצעות גישה דרך תת-מערכת הזיכרון. עם זאת, התוצאה זהה: הקריאה שנמצאת בסיום הקישור rfi חייבת להתרחש לאחר הקריאה שבתחילת הקישור dep.

דוגמה לתרחיש כזה היא הסדר הבא:

`R ->dep W ->rfi R'`

בתלות dep התוצאה של `R` נדרשת לכתובת או לערך שבו הכתיבה `W` תשתמש.

המעבד עשוי לבצע את `R'` לפני `W`, זה אפשרי כי המעבד יכול לחזות או להעביר את הערך ש-`W` תכתוב ולהשתמש בו באופן מוקדם לטובת `R'`.

עם זאת, המעבד לא יכול לבצע את `R'` לפני `R`, כדי לבצע את `R'`, המעבד זקוק למידע שמספקת הקריאה `R` (למשל, כתובת או ערך), ולכן `R'` תלויה ישירות בתוצאה של `R`. המעבד גם צריך לדעת אם `W` ו-`R'` פועלים על אותו מיקום בזיכרון כדי למנוע שגיאות עקב ביצוע מוקדם מדי.

במקרה של תלות בקרה בין `R` ל-`W`, המעבד עשוי לבחור לבצע ספקולטיבית את `W` ואת `R'` מוקדם יותר, גם לפני ביצוע `R`. אם מתברר שהספקולציה שגויה (למשל, `W` לא הייתה צריכה להתבצע או `R'` קיבל ערך שגוי), המעבד פשוט מתקן את עצמו על ידי הפעלה מחדש או ביטול של `R'`.

##### ppo

הרעיון של היחס ppo הוא לספק סדר בקונטקסט של thread אחד.

ישנם מצבים רבים שבהם מעבד מחויב לבצע שתי הוראות לפי סדר התוכנית. ה-LKMM מאחד אותם ליחס ה-ppo, המקשר בין ההוראה המוקדמת של ה-po להוראה ה-po מאוחרת יותר, ולכן הוא יחס משנה של ה-po.

ה-`fence & int` מקשר בין גישה ב-pre-set לגישה ב-post-set של מחסום ב-thread שביצע את המחסום. 

ה-`po-unlock-lock-po & int` מקשר בין גישה של שחרור נעילה לחלק של הקריאה של נעילה באותו thread.

#### Propagation: Ordering from release operations and strong fences
   

```ocaml {linenos=inline}
let A-cumul(r) = (rfe ; [Marked])? ; r
let rmw-sequence = (rf ; rmw)*
let cumul-fence = [Marked] ; (A-cumul(strong-fence | po-rel)
	| wmb | po-unlock-lock-po) ; [Marked] ; rmw-sequence
let prop = [Marked] ; (overwrite & ext)? ; cumul-fence* ;
	[Marked] ; rfe? ; [Marked]
```

##### A-cumulcumul-fence

כאן ה-A-cumulativity בא לידי ביטוי ב-`A-cumul(r)` שמגדיר שקריאה מתוך כתיבה ממעבד אחר (`rfe`) ואחריה אירוע מסומן (`Marked`) ואחריו מגיע יחס `r` שהוא היחס של המחסומים עם התנהגות A-cumulativity. צריך לשים לב שהקישור כאן ל-`r` הוא מוגבל ל-0 או ל-1 (בגלל האופרטור `?`) וזה גורם לכך שהקישור חייב להיות ישיר.


##### rmw-sequence
-complete/redo
היחס `rmw-sequence` כמו השם שלו מקשר בין רצפי rmw, שרצף `rmw` הוא סדרת עדכונים אטומיים שבה כל עדכון קורא מהעדכון הקודם לו. כאשר אנו מייצגים את הרצפים האלו באמצעות אירועים, זה מתואר כך:

$$
W_{Z_{0}} \to_{\textrm{rf}} R_{Y_{1}} \to_{\textrm{rmw}} W_{Z_{1}} \to_{\textrm{rf}} ...\to_{\textrm{rf}} R_{Y_{n}} \to_{\textrm{rmw}} W_{Z_{n}}
$$

במשמעות זו:

- ה-`Z0` הוא אירוע store כלשהו ו-n יכול להיות כל מספר (גם 0). 
- ה-`rf` מייצג קשר של read-from שבו הקריאות `Y1`, `Y2`, וכו' מתבצעת מתוך הכתיבה `Z0`, `Z1`, וכו'.
- ה-`rmw` מייצג את הקשר בין קריאה לכתיבה באותם עדכונים אטומיים.

הרצפים האלו מבטיחים שהאופי האטומי של העדכונים נשמר, כך שכל עדכון יכול לעקוב אחרי העדכון הקודם שלו בסדר הנכון.

היחס $W_{Z_{0}} \to_{\textrm{rmw-sequence}} W_{Z}$ נותן אינדיקציה לכך ש-`Z0` ו-`Zn` הם stores לאותו משתנה.


##### cumul-fence
היחס `cumul-fence` מגדיר את כל המחסומים שיש להם התנהגות מסוימת של cumulativity.

היחס בנוי מאיחוד של מחסומים עם מאפייני A-cumulativity יחד עם מחסום wmb שיש לו מאפייני cumulativity (במודל החזק ל-wmb היה מאפיין B-cumulativity) ובנוסף גם מאחדים את `po-unlock-lock-po`.

צריך לשים לב שהחלקים המאוחדים האלו צריכים להתחיל ולהסתיים בגישה מסומנת לזיכרון.

לאחר האיחוד של כל אלה יכול להיות `rmw-sequence`, השימוש ברצפי `rmw` ב-`cumul-fence` מראה תכונה מיוחדת במודל הזיכרון LKMM: רצפי `rmw` יכולים להרחיב את הקשר `cumul-fence`. כלומר, אם יש לנו את הקשרים הבאים:


- $W_{U} \to_{\textrm{cumul-fence}} W_{X} \to_{\textrm{rmw-sequence}} W_{Y}$
- $W_{U} \to_{\textrm{cumul-fence}} W_{Y}$

כשחושבים על זה במונחים של המודל האופרטיבי, $W_{U} \to_{\textrm{cumul-fence}} W_{Y}$ אומר שהכתיבה `U` מתפשטת לכל מעבד לפני שהכתיבה `X` עושה זאת. אז העובדה ש-`X` ו-`Y` מקושרים על ידי רצף rmw פירושה ש-`U` מתפשטת גם לכל מעבד לפני ש-`Y` מתפשט. באופן אנלוגי, רצפי rmw יכולים גם להרחיב את הקשר `w-post-bounded` .

בנוסף ה-LKMM דורש כש-$W_{a} \to_{\text{cumul-fence}} W_{b}$ אז $W_{a}$ חייב להתפשט למעבד נתון לפני $W_{b}$, אבל במעבדים שונים $W_{b}$ יכול להתפשט לפני $W_{a}$.


עוד תכונה שיכולה לעזור להבין את הרעיון של cumulativity היא הסגירות של A-cumulative ו-B-cumulative:
###### סגירות תחת `rfe^-1` של A-cumulative

ההגדרה של מחסום A-cumulative אומרת שה-pre-set שלו סגורה תחת `rfe^-1`. כלומר, אם R היא קריאה ב-pre-set של מחסום A-cumulative וקיים קישור $\text{W} \to \text{R}$ ב-`rfe`, אז גם הכתיבה W חייבת להיות ב-pre-set של המחסום.

הסיבה לכך ברורה: בגלל ש-R נמצאת ב-pre-set של המחסום, עליה להקדים את המחסום בסדר התוכנית ולהתבצע לפניו. אם R קוראת מ-W, הכתיבה W חייבת להיות גלויה למעבד שבו מבוצע המחסום לפני ש-R מבוצעת, ומכאן שגם הכתיבה צריכה להתבצע לפני שהמחסום עצמו מתבצע, ולכן לפי הגדרת A-cumulativity, הכתיבה W חייבת להיות חלק מה-pre-set של המחסום.

$$
\begin{aligned}
W \to_{\text{rfe}} R \\
R \in \text{A-cumul} \\
\text{rfe} = \{(R, W)\} \\
\text{rfe} ^{-1} = \{(W, R)\} \\
\Downarrow \\
W \in \text{A-cumul} \\
\end{aligned}
$$


סגירות תחת `rfe^-1` אינה טרנזיטיבית, כי לא ייתכן שיהיו שני קישורים $\text{X} \to \text{Y}$ ו-$\text{Y} \to \text{Z}$ ב-`rfe`, שכן Y לא יכולה להיות גם קריאה וגם כתיבה.

###### סגירות תחת `hb` של B-cumulative

ה-post-set של מחסום B-cumulative סגור תחת hb. כלומר, אם X נמצא ב-post-set של מחסום B-cumulative וקיים קישור $\text{Y} \to \text{X}$ ב-hb, אז גם Y חייב להיות חלק מה-post-set של המחסום.

$$
\begin{aligned}
X \to_{\text{hb}} Y \\
X \in \text{B-cumul} \\
\Downarrow \\
Y \in \text{B-cumul} \\
\end{aligned}
$$




מכיוון ש-X נמצא ב-post-set, המחסום מתפשט למעבד של X לפני ש-X מבוצע.

- אם $\text{X} \to \text{Y}$ הוא קישור hb שאינו `rfe`, אז Y נמצא על אותו מעבד שבו נמצא X, ומתבצע אחרי ש-X מתבצע, כלומר אחרי שהמחסום התפשט למעבד.
- אם $\text{X} \to \text{Y}$ הוא `rfe`, אז X היא כתיבה ו-Y היא קריאה מאותו X, אך על מעבד אחר. מאחר ש-X נמצאת ב-post-set, המחסום חייב להתפשט למעבד של Y לפני ש-X מתבצע, ומכאן גם לפני ש-Y מתבצע.  

בכל אחד מהמקרים, לפי הגדרת B-cumulativity, ההוראה Y חייבת להיות ב-post-set של המחסום.

סגירות תחת hb היא תכונה טרנזיטיבית. אם $\text{X} \to \text{Y}$ ו-$\text{Y} \to \text{Z}$ הם קישורים ב-hb, אז אם X נמצאת ב-post-set של מחסום B-cumulative, גם Y וגם Z חייבים להימצא שם.  

עבור מחסומי B-cumulative, התכונה שה-post-set סגורה תחת hb היא קריטית. במקרים שבהם ההוראות הן על מעבדים שונים, קשר hb לא מסתכם רק בכך ש-X מתבצעת לפני Y.
כדי שתהיה סגירות hb בין מעבדים שונים, יש צורך שמחסום B-cumulative שהתפשט למעבד של X לפני ביצועו יתפשט גם למעבד של Y לפני ביצועו. קשר זה נובע ממנגנון סיבתי בין המעבדים, כמו כתיבה במעבד של X לאחר ביצועו שנקראת במעבד של Y לפני ביצועו.

הסיבה לכך שהחלק הבין-מעבדי היחיד בהגדרת hb הוא `rfe` היא משום שהוא מייצג את המנגנון שמבטיח את הקשר הסיבתי הדרוש בין המעבדים.



 X \to_{\text{po}} \text{Rel}_{F} \\ \\ 
 
##### Prop
-complete/redo
https://diy.inria.fr/linux/long.pdf

היחס `prop` מייצג את רעיון הטרנזיטיביות. הוא יוצר קשר בין אירועים, שעשויים להתרחש ב-thread-ים שונים.

היחס `prop` מרחיב את מושג ההצטברות, הוא מבטיח שההבטחות שסופקו על ידי `cumul-fence` בתוך thread מסוים T יתפשטו ל-thread-ים אחרים הניגשים לאותם משתנים כמו ש-T ניגש.

במילים פשוטות, `prop` יוצר קשרים מעבר ל-thread הבודד שבו אירועי הסדר התרחשו, ומחיל את ההשפעות של הסדר הזה על thread-ים נוספים שמשתפים גישה למשתנים משותפים.

היחס `prop` מקשר בין שני אירועים במעבד P כאשר פעולת כתיבה שמתבצעת במעבד אחר מגיעה לאחר האירוע הראשון לפי **סדר הקוהרנטיות**, ומתפשטת למעבד P לפני שהאירוע השני מתרחש.

ההגדרה הפורמלית של יחס `prop` כוללת קשר אופציונלי של coe או fre, ואחריהם מספר שרירותי של קשרים cumul-fence, שנעצר בקשר rfe אופציונלי.

###### דוגמה 1

```c {linenos=inline}
C MP+relacq??

{
	int x;
}

P0(int *x)
{
	int r1;

	WRITE_ONCE(*x, 1);
	r1 = READ_ONCE(*x); // 8
}

P1(int *x)
{
	WRITE_ONCE(*x, 8);
}

exists (0:r0=8)
```

אם בסיום הערך של `r1` הוא 8, אז הגישה של P0 חייבת להתבצע לפי סדר התוכנית.  
נוכל להסיק זאת מתוך המודל האופרטיבי: אם פעולת הקריאה של P0 הייתה מבוצעת לפני פעולת הכתיבה שלו, אז הערך שנכתב היה מועבר לקריאה, ובסופו של דבר r1 היה שווה ל-1, ולא ל-8.  
במקרה הזה, יש קשר `prop` בין פעולת הכתיבה של P0 לפעולת הקריאה שלו, משום שפעולת הכתיבה של P1 התרחשה אחרי הכתיבה של P0 לפי סדר הקוהרנטיות של x, והכתיבה של P1 התפשטה למעבד P0 לפני שפעולת הקריאה של P0 בוצעה.

###### דוגמה 2

```c {linenos=inline}
C MP+relacq??

{
	int x = 0;
}

P0(int *x)
{
	r1 = READ_ONCE(*x); // 0
	r2 = READ_ONCE(*x); // 9
}

P1(int *x)
{
	WRITE_ONCE(*x, 9);
}

exists (0:r1=0 /\ 0:r2=9)
```


אם בסיום הערכים הם `r1 = 0` ו-`r2 = 9`, אז הגישה של P0 חייבת להתבצע לפי סדר התוכנית.  
אם פעולת הקריאה השנייה הייתה מתבצעת לפני הראשונה, אז הכתיבה `x = 9` הייתה חייבת להתפשט למעבד P0 לפני ביצוע הקריאה הראשונה, ולכן r1 היה שווה ל-9 ולא ל-0.  
במקרה הזה, יש קשר `prop` בין פעולת הקריאה הראשונה של P0 לשנייה, משום שפעולת הכתיבה של P1 החליפה את הערך שנקרא על ידי הקריאה הראשונה של P0, והכתיבה של P1 התפשטה למעבד P0 לפני ביצוע הקריאה השנייה של P0.

###### דוגמה 3

```c {linenos=inline}
int buf = 0, flag = 0;

P0()
{
	WRITE_ONCE(buf, 1);
	smp_wmb();
	WRITE_ONCE(flag, 1);
}

P1()
{
	int r1;
	int r2;

	r1 = READ_ONCE(flag); // 1
	r2 = READ_ONCE(buf); // 0
}
```

זה דפוס של MP, עם מחסום smp_wmb בין שתי פעולות הכתיבה. אם בסוף הערכים הם `r1 = 1` ו-`r2 = 0`, אז יש קשר `prop` בין הקריאה השנייה של P1 לקריאה הראשונה שלו (אחורה). הסיבה לכך דומה לדוגמאות קודמות: הערך ש-P1 קרא מ-buf הוחלף על ידי פעולת הכתיבה של P0 ל-buf. הגדר מבטיחה שפעולת הכתיבה ל-buf תתפשט ל-P1 לפני שפעולת הכתיבה ל-flag תתפשט, ושהכתיבה ל-flag תתפשט ל-P1 לפני ש-P1 יקרא את ה-flag.

הקשר `prop` אומר שכדי לקבל את התוצאה `r1 = 1` ו-`r2 = 0`, על המעבד P1 לבצע את הקריאה השנייה שלו לפני הראשונה. אכן, אם הקריאה מ-flag הייתה מתבצעת קודם, אז הכתיבה `buf = 1` כבר הייתה מתפשטת ל-P1 בזמן ביצוע הקריאה מ-buf, ובסופו של דבר r2 היה שווה ל-1 ולא ל-0.

אבל מה יקרה אם נוסיף מחסום smp_rmb בין הקריאות של P1? המחסום יחייב את שני הקריאות להתבצע לפי סדר התוכנית, ויצור מחזור בקשרים של hb: המחסום יצור קשר ppo בין הקריאה הראשונה לשנייה, ויחסי prop ייצרו קשר hb מהקריאה השנייה הראשונה. מכיוון שהוראה לא יכולה להתבצע לפני עצמה, ניאלץ להסיק שבמקרה כזה, הוספת מחסום smp_rmb תעשה את התוצאה `r1 = 1` ו-`r2 = 0` לבלתי אפשרית, כפי שזה אמור להיות.

###### דוגמה 4

```c {linenos=inline}
C MP+relacq??

{
    int x;
    int y;
    int z;
}


P0(int *x, int *y, int *z)
{
    int r0;
	WRITE_ONCE(*x, 1); // W0
	r0 = READ_ONCE(*z); // R0
}

P1(int *x, int *y, int *z)
{	
    int r0;
    WRITE_ONCE(*x, 2); // W1
    smp_wmb();
    WRITE_ONCE(*y, 1); // W2
}

P2(int *x, int *y, int *z)
{	
    int r1;
    r1 = READ_ONCE(*y); // R1
    smp_store_release(z, 1); // W3
}



exists (0:r0=1 /\ 2:r1=1 /\ x=2)
```

אם `x = 2`, `r0 = 1`, ו-`r1 = 1` לאחר שהקוד הזה רץ, אז יש קשר `prop` בין פעולת הכתיבה של P0 לפעולת הקריאה שלו. הסיבה לכך היא שפעולת הכתיבה של P0 הוחלפה על ידי פעולת הכתיבה של P1, כיוון ש-`x = 2` בסוף (קשר coe). המחסום smp_wmb מבטיח שפעולת הכתיבה של P1 ל-x תתפשט ל-P2 לפני שפעולת הכתיבה ל-y תתפשט לשם (הקשר cumul-fence הראשון). לאחר מכן, הכתיבה ל-y מתפשטת ל-P2 לפני שפעולת הקריאה של P2 וכתיבתו מבוצעות. ה-smp_store_release של P2 מבטיח שפעולות הכתיבה ל-x ול-y יתפשטו ל-P0 לפני שפעולת הכתיבה ל-z תתפשט. לבסוף, הקריאה של P0 מתבצעת לאחר שפעולת הכתיבה ל-z התפשטה ל-P0 (קשר rfe).



כדי לראות את זה בדרך פורמלית אפשר לבדוק את היחסים בין ההוראות, זה בא לידי ביטוי בצורה הבאה:

דבר ראשון נאסוף את כל היחסים הבסיסים:

$$
\begin{aligned}
% Event_{cpu}(args...)
W_{0}(x,1) \to_{coe} W_{1}(x,2) \\
W_{1}(x,2) \to_{wmb} W_{2}(y,1) \\
W_{2}(y,1) \to_{rfe} R_{1}(y) \\
R_{1}(y) \to_{po-rel} W_{3}(z,1) \\
W_{3}(z,1) \to_{rfe} R_{0}(z) \\
% \Downarrow \\
\end{aligned}
$$

לאחר מכן נבדוק את התוכנות של המחסומים כי אנחנו יודעים ששניהם מספקים cumulativity:

```ocaml {linenos=inline}
let po-rel = [M] ; po ; [Release]
let wmb = [W] ; fencerel(Wmb) ; [W]

let A-cumul(r) = (rfe ; [Marked])? ; r
let rmw-sequence = (rf ; rmw)*
let cumul-fence = [Marked] ; (A-cumul(strong-fence | po-rel) | wmb | po-unlock-lock-po) ; [Marked] ; rmw-sequence
```


נצמצם דברים שלא רלוונטים אלינו ב-`cumul-fence`:

```
let cumul-fence = (A-cumul(po-rel) | wmb)
```


נתחיל לחבר את ההגדרות ביחד ונקבל

```ocaml {linenos=inline}
let cumul-fence = 
	(((rfe ; [Marked])? ; po-rel) |
	wmb)
```


ולאחר מכן אפשר להציב ולקבל ששתי המחסומים באמת נמצאים ב-`cumul-fence`.

כלומר:

$$
\begin{aligned}
W_{1}(x,2) \to_{cumul-fence} W_{2}(y,1) \\
W_{2}(y,1) \to_{cumul-fence} W_{3}(z,1) \\
\Downarrow \\
W_{1}(x,2) \to_{cumul-fence*} W_{3}(z,1)
\end{aligned}
$$
 

ועכשיו נחבר את היחסים ונבדוק אם קיימים יחסי `prop`:

```ocaml {linenos=inline}
let prop = ((co | fr) & ext)? ; cumul-fence* ; rfe?
```


$$
\begin{aligned}
% Event_{cpu}(args...)
W_{0}(x,1) \to_{coe}
W_{1}(x,2) \to_{cumul-fence}
\\
W_{2}(y,1) \to_{cumul-fence}
W_{3}(z,1) \to_{rfe}
R_{0}(z)
\\
\Downarrow \\
W_{0}(x,1) \to_{prop} R_{0}(z)

\end{aligned}
$$


ובאמת יש כאן יחס prop.

היחס prop אומר שיש "התפרצות" של כתיבה חיצונית בין 2 אירועים באותו מעבד שהמידע "שמתפרץ" מתפשט על ידי מעבד אחר למעבד המדובר. כלומר האירוע הראשון צריך לרוץ לפני ההתפשטות של המידע והאירוע השני צריך לרוץ אחרי ההתפשטות של המידע.





#### Happens Before: Ordering from the passage of time
-complete/redo

```ocaml {linenos=inline}
let hb = [Marked] ; (ppo | rfe | ((prop \ id) & int)) ; [Marked]
acyclic hb as happens-before
```

היחס `hb` (או happens-before) הוא יחס שנותן סדר על פני זמן, כלומר הוא נותן יחס של זמן בין אירועים.

היחס hb הוא האיחוד של יחסי ppo ו-rfe, יחד עם prop מוגבל לאירועים שונים באותו thread. אקסיומת hb דורשת ש-hb יהיה א-ציקלי, מה שמבטיח ש-rf תואם הוראות מקומיות לאחר ppo ומחסומים.

ההתחלה והסוף של `hb` עם `[Marked]` כדי לספק תמיכה בזיהוי data-race, והתוכן עצמו של היחס הוא איחוד בין ה-ppo שנותן סדר פנימי למעבד, ה-rfe שנותן יחס זמני בגלל סיבתיות ויחס ה-prop שמסדר את ההתפשטות של המידע על פני מעבדים.

כאשר יש `W ->rfe R`, אז W ו-R מתרחשים במעבדים שונים, כדי ש-R יוכל לקרוא את הערך שנכתב על ידי W, יש לוודא שפעולת הכתיבה של W התפשטה למעבד שבו R מתבצע לפני ש-R בוצע בפועל. כתוצאה מכך, W חייבת להתבצע לפני R, ולכן מתקיים הקשר `W ->hb R`.

כאשר `W ->rfi R`, אז W ו-R מתרחשים באותו מעבד, ההנחה של hb לא בהכרח תקפה. במקרים כאלה, המודל מאפשר להעביר (forwarding) את הערך של W ישירות ל-R, מה שיכול לגרום ל-R להתבצע לפני ש-W בוצעה לחלוטין.

קשרים מסוג `coe` ו-`fre` אינם נכללים ב-hb, למרות הדמיון שלהם ל-`rfe`:

- כש-`W ->coe W'` אז שתי הכתיבות פעולות לאותו מיקום זיכרון אך במעבדים שונים, כאשר W מופיעה לפני W' בסדר הקוהרנטיות. עם זאת, ייתכן ש-W' תתבצע בפועל לפני W, מכיוון "שההחלטה" איזו כתיבה מחליפה את השנייה נעשית על ידי תת-מערכת הזיכרון.

- כש-`R ->fre W` אז W היא כתיבה שמחליפה את הערך שנקרא על ידי R. זה לא אומר ש-W חייבת להתבצע לאחר R; תת-מערכת הזיכרון צריכה רק למנוע את הפצת W למעבד שבו R מתבצע עד לאחר ש-R סיים את פעולתו. זה אפשרי אם W מבוצעת זמן קצר לפני R.

זה בגלל שיש השפעה של הזמן שלוקח למידע להתפשט אז ההרצה של ההוראה לא קשורה בקשר הדוק להתפשטות של האפקט של ההוראה, אז בגלל זה יכול להיות שההוראה רצה אבל המידע לא הספיק להגיע (להתפשט) למעבד אחר ולכן הוא יראה ערך ישן ולכן זה יחס שלא מחייב יחס של זמן התרחשות של אירועים.

בגלל ש-hb הוא זמני אסור לו להיות מעגלי ולכן הוא מסומן כאציקלי (acyclic):

```ocaml {linenos=inline}
acyclic hb as happens-before
```



### Write and fence propagation ordering
-complete/redo

 
#### Propagation

```ocaml {linenos=inline}
(* Propagation: Each non-rf link needs a strong fence. *)
let pb = prop ; strong-fence ; hb* ; [Marked]
acyclic pb as propagation
```

היחס pb מגדיר קשר בין אירועים שמתחיל בפעולת prop, ואחריה מחסום חזק, ואחריו רצף שרירותי של קשרי hb. האקסיומה של pb מחייבת שהקשר הזה יהיה א-ציקלי, מה שמבטיח שהאירועים יידרסו (overwritten) באופן שמכבד את סדר הזיכרון המתבקש, הנכפה על ידי המחסומים החזקים.




דוגמה טובה הממחישה איך pb עובד היא תבנית ה-SB עם מחסומים חזקים:

```c {linenos=inline}
int x = 0, y = 0;

P0()
{
	int r0;
	
	WRITE_ONCE(x, 1);
	smp_mb();
	r0 = READ_ONCE(y);
}

P1()
{
	int r1;

	WRITE_ONCE(y, 1);
	smp_mb();
	r1 = READ_ONCE(x);
}
```


אם בסיום התוכנית הערך של `r0` הוא 0, זה אומר שנוצר קשר `pb`  בין פעולת הקריאה של P0 לפעולת הקריאה של P1. הקשר הזה מבוסס על שלושה אירועים:

1. קשר `fre` שמחבר את פעולת הקריאה של P0 לכתיבה של P1, אשר מחליפה את הערך שנקרא על ידי P0.
2. מחסום חזק הממוקם בין פעולת הכתיבה של P1 לבין הקריאה שלו.

בדוגמה זו, השרשראות של קשרים מסוג `cumul-fence` ו-`hb` נשארות ריקות.  

שימו לב שהקשר `pb` לא נחשב כחלק מ-`hb` תחת הקטגוריה של `prop`, מכיוון שהוא לא מתחיל ומסתיים באותו מעבד.

באופן דומה, אם הערך של `r1` הוא 0 בסוף, ישנו קשר `pb` בין הקריאה של P1 לפעולת הקריאה של P0. 

מצב זה מוביל לכך שאם גם `r0` וגם `r1` היו שווים ל-0, היה נוצר מחזור בגרף `pb`, דבר שאינו אפשרי כי הוראה לא יכולה להתרחש לפני עצמה.

לכן, הוספת מחסומי `smp_mb()` לתבנית SB מבטיחה למנוע את התוצאה שבה `r0 = 0` ו-`r1 = 0`.




---


### גישה רגילה ו-data races
-complete/redo

https://github.com/torvalds/linux/blob/master/tools/memory-model/Documentation/explanation.txt

במונחים טכניים, הקומפיילר מניח שבזמן ביצוע התוכנית, לא יתרחשו מירוצי נתונים (data races). מירוץ נתונים מוגדר כאשר מתקיימים התנאים הבאים:

1. ישנן שתי גישות לאותו מיקום בזיכרון.
2. לפחות אחת מהגישות היא פעולת כתיבה (store).
3. לפחות אחת מהגישות היא רגילה (plain).
4. הגישות מתבצעות על מעבדים שונים (או ב-thread-ים שונים על אותו מעבד).
5. הגישות מבוצעות בו-זמנית.

בספרות, אם שתי גישות עומדות בתנאים 1 ו-2, נאמר שהן "מתנגשות" (conflict). אנו מרחיבים את המושג וקוראים לשתי גישות "מועמדות למירוץ" אם הן עומדות בתנאים 1–4. השאלה אם שני מועמדים למירוץ אכן יוצרים מירוץ תלויה בכך שהם מתבצעים בו-זמנית.

ה-LKMM מנסה לזהות אם בתוכנית יש מועמדים למירוץ שיכולים להתבצע במקביל. אם נמצא כזה מצב, ה-LKMM מסיק שקיים מירוץ נתונים פוטנציאלי ואינו מספק תחזית לגבי תוצאת התוכנית.

הגדרת מועמדים למירוץ היא פשוטה יחסית, שכן כל המושגים הנדרשים להגדרה כלולים כבר במודל הזיכרון. עם זאת, האתגר האמיתי הוא לקבוע אם גישות אלו עשויות להתבצע במקביל. ה-LKMM נוקט גישה שמרנית, ומניח שגישות עשויות להתבצע במקביל אלא אם ניתן להוכיח אחרת.

אם שתי גישות לזיכרון אינן מתבצעות במקביל, אחת מהן חייבת להתרחש לפני השנייה. על בסיס זה, ה-LKMM קובע ששתי גישות אינן מקבילות אם ניתן לקשר ביניהן באמצעות שרשרת של קישורים מסוג hb, pb, ו-rb (המכונים יחד xb, לציון executes before). עם זאת, קיימים שני מצבים מורכבים:
#### דרישת התפשטות וביצוע לפני

אם הגישה הראשונה, X, היא קריאה והגישה השנייה, Y, היא כתיבה, אין חשש שהן מקבילות. הסיבה לכך היא ש-Y אינה יכולה להשפיע על הערך ש-X קוראת, אלא אם כן הערך של Y יופץ לזיכרון המשותף ולמעבד שמבצע את X. פעולה זו תתרחש רק לאחר השלמת Y, ולכן בהכרח לאחר ש-X כבר בוצעה.

לעומת זאת, אם X היא כתיבה, גם אם X מתבצעת לפני Y, עדיין ייתכן ש-X תתפשט לזיכרון בדיוק בזמן ש-Y מבוצעת. במקרה כזה, X עשויה לשנות את ההתנהגות של Y, ולכן יש להתייחס אליהן כפעולות מקבילות.

לכן, במקרה שבו X היא כתיבה, כדי ש-X ו-Y לא ייחשבו מקבילות, נדרש לא רק ש-X תבוצע לפני Y, אלא גם ש-X תתפשט למעבד שמבצע את Y לפני ש-Y תתחיל. באופן דומה, אם Y מתבצעת לפני X, אז Y חייבת להתפשט למעבד שמבצע את X לפני ש-X תתבצע.

#### יחס הנראות (vis)

```ocaml {linenos=inline}
(* Executes-before and visibility *)
let xbstar = (hb | pb | rb)*
let vis = cumul-fence* ; rfe? ; [Marked] ;
	((strong-fence ; [Marked] ; xbstar) | (xbstar & int))
```

היחס `xbstar` הוא פשוט  כמו שהוא נשמע: `xb` עם סיומת `*` (כלומר יכול להיות בכל אורך)

ההגדרה של vis בנויה על ידי `cumul-fence` בכל כמות ולאחריו `rfe` אופציונלי שחייב להסתיים באירוע מסומן (ואם ה-`rfe` ריק עדיין צריך להיות אירוע מסומן) ולאחריו איחוד של 2 אפשרויות:
- אפשרות של מחסום חזק (`strong-fence`) ואז `xbstar` והאירוע ביניהם הוא מסומן.
- יחס `xbstar` פנימי




 
הגדרת vis מבוססת על מספר עקרונות בסיסיים הנוגעים למחסומי זיכרון ולהתפשטות של פעולות בין מעבדים:

1. מחסומי זיכרון מסוג cumul-fence מבטיחים שכתיבות שמופיעות לפני המחסום בסדר התוכנית יתפשטו לכל המעבדים לפני כתיבות שמופיעות לאחר המחסום בסדר התוכנית

2. אם יש קישור rfe מכתיבה W לקריאה R, המשמעות היא ש-R קורא את הערך שנכתב ב-W. מצב זה מחייב את W להתפשט למעבד שבו מתבצעת R לפני ש-R תוכל לקרוא את הערך.

3. מחסומי זיכרון חזקים מבטיחים שכתיבות שנמצאות לפני המחסום (או שמתפשטות למעבד שבו המחסום מבוצע) יגיעו לכל המעבדים לפני שאירועים שלאחר המחסום יוכלו להתבצע.

##### דוגמת MP

נבחן את הדוגמה של דפוס MP (הכוללת מחסומים ותוויות להצהרות):

```c {linenos=inline}
int buf = 0, flag = 0;

P0()
{
	X: WRITE_ONCE(buf, 1);
	   smp_wmb();
	W: WRITE_ONCE(flag, 1);
}

P1()
{
	int r1;
	int r2 = 0;

	Z: r1 = READ_ONCE(flag);
	   smp_rmb();
	Y: r2 = READ_ONCE(buf);
}
```


1. מחסום הזיכרון smp_wmb(): יוצר קישור cumul-fence בין הפעולה X (כתיבה ל-buf) לפעולה W (כתיבה ל-flag).
2. אם בסוף הביצוע `r1 = 1`, אז יש קישור rfe מ-W (הכתיבה ל-flag) ל-Z (הקריאה של flag). זה מחייב את הכתיבה X (ל-buf) להתפשט ממעבד P0 למעבד P1 לפני ש-Z מבוצע.
3. האירועים Z ו-Y נמצאים על אותו מעבד, והמחסום smp_rmb() מספק קישור xb מ-Z ל-Y, כלומר, הוא מבטיח ש-Z יבוצע לפני Y.

באמצעות הקישורים הללו, מתקיים `X ->vis Y`. כלומר, הפעולה X חייבת להתפשט למעבד של Y (מעבד P1) לפני ש-Y (קריאה מ-buf) תתבצע בפועל.


#### גישה Plain

כאשר עוסקים במירוצי נתונים, אחת המורכבויות נובעת מהשימוש בגישה plain לזיכרון. עד כה, מרבית היחסים שהוגדרו על ידי ה-LKMM (כגון ppo, hb, prop, cumul-fence, pb, vis ועוד) התייחסו רק לגישה מסומנת (marked). עם זאת, גישות plain מציגות אתגר ייחודי, בעיקר בשל חופש הפעולה של הקומפיילר.

#### התנהגות הקומפיילר

הקומפיילר רשאי לבצע טרנספורמציות רבות על גישה פשוטה, כולל:

- שילוב גישות פשוטות.
- פיצול גישות לפעולות קטנות יותר.
- שכפול גישות.
- הסרה של גישות לא נדרשות.
- יצירת גישות חדשות.

למעשה, הופעת גישה פשוטה בקוד המקור לא מבטיחה דבר לגבי האופן שבו היא תתבטא בקוד האובייקט (הוראות המכונה).

#### מגבלות על הקומפיילר

למרות חופש הפעולה, הקומפיילר מחויב לכמה מגבלות:

1. **מירוצי נתונים**: הקומפיילר אינו יכול ליצור מירוץ נתונים בקוד האובייקט אם לא קיים מירוץ נתונים בקוד המקור. אם היה חופשי לעשות זאת, מודלי זיכרון היו חסרי תועלת, וקוד מרובה thread-ים היה מסוכן ולא צפוי.

2. **מחסומי קומפיילר**: הקומפיילר אינו רשאי להעביר גישה רגילה מעבר למחסום קומפיילר.

הפונקציה `barrier()` היא מחסום קומפיילר בקרנל והיא מבטיחה שכל הוראות המכונה של קבוצת הגישות הראשונה יושלמו לפני הוראות המכונה של קבוצת הגישות השנייה. הדבר נכון גם אם חלק מהגישות הן plain.
#### דוגמה

הדוגמה הזו מדגימה כיצד ניתן לנתח מירוצי נתונים בתוכנית. בואו נבחן את דפוס MP, אך הפעם עם גישה רגילה עבור משתנה `buf`:

```c {linenos=inline}
int buf = 0, flag = 0;

P0()
{
	U: buf = 1;
	   smp_wmb();
	X: WRITE_ONCE(flag, 1);
}

P1()
{
	int r1;
	int r2 = 0;

	Y: r1 = READ_ONCE(flag);
	   if (r1) {
		   smp_rmb();
		V: r2 = buf;
	   }
}
```


תוכנית זו אינה מכילה מירוץ נתונים, למרות שגישות U ו-V עשויות להיראות כמו מועמדות למירוץ. ה-LKMM יכול להוכיח שהן אינן במקביל באופן הבא:

1. האירועים X ו-Y הן גישות מסומנות, והם עם קישור `rfe` מ-X ל-Y ושתי העובדות האלו הן הוכחה תקפה לכך ש-X התפשט ל-P1 לפני ביצוע Y. כלומר, `X ->vis Y`. אם לא היה קישור `rfe`, אז r1 היה 0, מה שגורם ל-V לא להתבצע, ובכך נמנע מירוץ נתונים בין U ל-V.

2. הגדרת המחסום `smp_rmb()` ב-P1 משמשת גם כגדר קומפיילר וגם כמחסום זיכרון. זה מבטיח שכל ההוראות ברמת המכונה שמתאימות לגישה V יתבצעו אחרי הגדר, כלומר, אחרי ביצוע Y.

ה-store ל-`buf` שבוצע ב-U חייב להתפשט ל-P1 לפני שיתבצע ה-load ב-V (בהנחה ש-V יתבצע). זאת שוללת את האפשרות למירוץ נתונים בין הגישות U ו-V.


הניתוח הזה מציג כיצד ה-LKMM מטפל בגישה רגילה באופן כללי. נניח ש-R היא קריאה plain ואנחנו רוצים להראות ש-R מתבצע לפני גישה מסומנת E. אפשר לעשות זאת על ידי מציאת גישה מסומנת X כך ש-R ו-X מסודרות על ידי גדר מתאימה ו-`X ->xb* E`. אם E הייתה גם גישה רגילה, היינו מחפשים גישה מסומנת Y כך ש-`X ->xb* Y`, ו-Y ו-E יהיו מסודרות על ידי גדר. סידור זה נקרא בכך ש-R היא post-bounded (תחומה אחרי) על ידי X ו-E היא pre-bounded (תחומה לפני) על ידי Y.


הערה:
	הכוונה בשמות post ו-pre היא כלפי הפעולות המסומנת, כלומר אם יש יחס `w-post-bounded` אז הפעולה הראשונה היא רגילה והשניה היא מסומנת.

מכיוון ש-R היא קריאה, אנחנו אומרים ש-R היא `r-post-bounded` על ידי X. באופן דומה, E תהיה `r-pre-bounded` או `w-pre-bounded` על ידי Y, תלוי אם E הייתה store או load. ההבחנה הזו חשובה כי מחסומים מסוימים משפיעים רק על loads (כמו smp_rmb()) וחלקם משפיעים רק על stores (כמו smp_wmb()); אם לא כן, הגבולות של שני סוגי הגישות היו זהים. במקרה מנוון, אם למשל R הייתה load מסומנת, אז אפשר לראות ש-X הוא R עצמו.

הצורך להבחין בין `r-bounding` ל-`w-bounding` מציף בעיה נוספת. כאשר קוד המקור מכיל כתיבה plain, הקומפיילר עשוי להכניס loads רגילים מאותו מיקום לקוד האובייקט. לדוגמה, אם בקוד המקור יש את השורה:

```c {linenos=inline}
x = 1;
```

הקומפיילר עשוי להמיר זאת לקוד אובייקט שייראה כך:

```c {linenos=inline}
if (x != 1)
	x = 1;
```


ה-LKMM מבטיח ש-store רגילה תהיה מוגבלת כ-`w-pre-bounded` או `w-post-bounded` על ידי גישה מסומנת, ובנוסף, דורש גם שה-store תהיה `r-pre-bounded` או `r-post-bounded`, כדי להתמודד עם מקרים בהם הקומפיילר מוסיף load.

אבל לא ידוע על מקרים בהם הקומפיילר הרחיב store עם load בצורה כזו.

בנוגע לטרנספורמציה אחרת, הוספת load רגיל על ידי הוספת store לאותו מיקום אסורה. הסיבה לכך היא שהקומפיילר לא יכול לדעת אם מעבדים אחרים עשויים לבצע load בו-זמנית מהמיקום הזה. שני loads בו-זמניים לא יוצרים מירוץ נתונים, אך store יכול להוות מרוץ עם load בו-זמני. לפיכך, הוספת store עשויה ליצור מירוץ נתונים חדש שבו לא היה קודם, דבר שהקומפיילר אסור לעשות. מצד שני, הגדלת store על ידי load מקובלת, כי פעולה כזו לא תיצור מירוץ נתונים אלא אם כן הוא כבר קיים בקוד המקור.

ה-LKMM כולל גם דרך נוספת לתחום לפני (pre-bound) גישה רגילה, בנוסף למחסומים. מדובר בתלות כתובת ב-load מסומנת. לדוגמה, ברצף הקוד:

```c {linenos=inline}
p = READ_ONCE(ptr);
r = *p;
```

ה-LKMM קובע כי ה-load המסומן של ptr מגביל את ה-load הרגיל של `*p`, כלומר, ה-load המסומן חייב להתבצע לפני כל הוראת מכונה שמתאימה ל-load הרגיל. זהו תנאי הגיוני, שכן המעבד לא יכול לבצע את ה-load של `*p` עד שהוא יודע את הערך של ptr. 

 חלק מהשימושים הנפוצים ב-RCU עלולים להיתפס כמירוצי נתונים. דוגמה לכך היא הקוד הבא: 

```c {linenos=inline}
int a = 1, b;
int *ptr = &a;

P0()
{
	b = 2;
	rcu_assign_pointer(ptr, &b);
}

P1()
{
	int *p;
	int r;

	rcu_read_lock();
	p = rcu_dereference(ptr);
	r = *p;
	rcu_read_unlock();
}
```

בדוגמה זו, הקריאות ל-rcu_read_lock() ו-rcu_read_unlock() לא מבצעות פעולה ממשית, כי אין תקופות חסד, והן משמשות רק לצורך הדגמה. בדרך כלל, P0 יקרא ל-synchronize_rcu() אחרי קריאת ה-rcu_assign_pointer().

הפונקציה rcu_assign_pointer() מבצעת store-release, כך שה-store הרגיל ל-b הוא `w-post-bounded` לפני ה-store ל-ptr, ושתי ה-stores יתפשטו ל-P1 בסדר הזה. עם זאת, הפונקציה rcu_dereference() היא שקולה ל-READ_ONCE(), שהיא גישה מסומנת, אך לא גדר או מחסום קומפיילר. כתוצאה מכך, ההנחה לגבי תלות כתובת היא מה שמבטיח שה-load של ptr ב-P1 מוגבל כ-`r-pre-bounded` לפני ה-load של `*p`, ובכך נמנע מירוץ נתונים.

זהו מצב שבו הקומפיילר יכול לשנות את התנהגות מודל הזיכרון, ולכן יש צורך בזהירות בעת בניית קוד כזה. במיוחד, השוואות בין מצביעים לכתובות ידועות עשויות לגרום לבעיות. לדוגמה, אם יש לך קוד כזה:

```c {linenos=inline}
p = rcu_dereference(ptr);
if (p == &x)
	r = *p;
```

הקומפיילר עשוי להמיר אותו לקוד כזה:

```c {linenos=inline}
p = rcu_dereference(ptr);
if (p == &x)
	r = x;
```

או אפילו:

```c {linenos=inline}
rtemp = x;
p = rcu_dereference(ptr);
if (p == &x)
	r = rtemp;
```

שזה מבטל את ההנחה במודל הזיכרון, מכיוון שהמעבד יכול לבצע את ה-load של x לפני ה-load של ptr, מה שלמעשה מפר את תלות הכתובת ברמה של מכונה (אם כי ייתכן שתהיה תלות בקרה).

בנוגע לכתיבה רגילה, יש מצב שבו היא לא חייבת להיות `w-post-bounded`: כאשר היא מופרדת מהגישה האחרת במועמד למרוץ על ידי מחסום. זה עשוי להיראות לא הגיוני במבט ראשון, כי כדי שגיאות יהיו מועמדות למרוץ, הן צריכות להתבצע במעבדים שונים, ומחסומים רגילים לא מקשרים אירועים במעבדים שונים. עם זאת, `rcu-fence` יכולה לשמש לכך. דוגמה לכך:

```c {linenos=inline}
int x, y;

P0()
{
	WRITE_ONCE(x, 1);
	synchronize_rcu();
	y = 3;
}

P1()
{
	rcu_read_lock();
	if (READ_ONCE(x) == 0)
		y = 2;
	rcu_read_unlock();
}
```

האם ה-stores הרגילים מתחרים? ברור שלא. אם ב-P1 ה-READ_ONCE(x) קורא ערך שאינו אפס, אז נניח שהקריאה ל-READ_ONCE(x) אכן מחזירה 0. זה אומר שהקטע הקריטי בצד של P1 חייב להסתיים לפני תקופת החסד ב-P0, מכיוון שההבטחה של התקופת החסד ב-RCU מבטיחה שאם לא, ה-store של P0 ל-x היה מתפשט ל-P1 לפני שהקטע הקריטי ב-P1 החל, וכך היה נראה ל-READ_ONCE(x). (כמו כן, הקישור fre בין ה-READ_ONCE ל-WRITE_ONCE יוצר קשר של rcu בין שני האירועים הללו).

זה אומר שיש קשר של `rcu-fence` בין `y = 2` ב-P1 ל-`y = 3` ב-P0, מה שמחייב את הראשון להתפשט מ-P1 ל-P0 לפני שהשני יכול להתבצע. לכן, שני ה-stores לא יכולים להתבצע במקביל ואין מירוץ, למרות שה-store הפשוטה ב-P1 ל-y אינה `w-post-bounded` על ידי גישה מסומנת.

אם מחברים את כל החומר הזה יחד, מתקבלת התמונה הבאה: עבור שני stores מועמדים למירוץ, `W` ו-`W'`, כאשר:

`W ->co W'`

ה-LKMM קובע ש-ה-stores אינן מתחרות אם ניתן לקשר בין `W` ל-`W'` על ידי הרצף:

`w-post-bounded ; vis ; w-pre-bounded`
ניתן לראות את קישור הזה בא לידי ביטוי ב-`ww-vis`.

אם `W` הוא רגיל, אז גם הם צריכים להיות מקושרים על ידי הרצף:

`r-post-bounded ; xbstar ; w-pre-bounded`
ניתן לראות את קישור הזה בא לידי ביטוי ב-`rw-xbstar`.

אם `W'` הוא רגיל, אז הם צריכים להיות מקושרים על ידי הרצף:

`w-post-bounded ; vis ; r-pre-bounded`
ניתן לראות את קישור הזה בא לידי ביטוי ב-`wr-vis`.

במקרים של קריאה `R` וכתיבה `W` מועמדים למירוץ, ה-LKMM קובע ששתי הגישות אינן מתחרות אם ניתן לקשר את `R` ל-`W` על ידי הרצף:

`r-post-bounded ; xbstar ; w-pre-bounded`

או אם ניתן לקשר את `W` ל-`R` על ידי הרצף:

`w-post-bounded ; vis ; r-pre-bounded`

למקרים שכוללים קשר vis, ה-LKMM מקבל גם רצפים שבהם `W` מקושר ל-`W'` או `R` על ידי הרצף:

`strong-fence ; xbstar ; {w and/or r}-pre-bounded`

רצפים ללא `post-bounding`, וה-LKMM מאפשר לקישור פשוט להיות גדר ללא תוחם כלל. אם אין רצף מהסוג המתאים, ה-LKMM קובע שיש בגישה מירוץ.

יש עוד חלק אחד ב-LKMM הנוגע לגישה רגילה (אם כי לא למירוצי נתונים) שדורש התייחסות. כמו שציינו, קשרים רבים, כמו hb, מוגבלים רק לגישות מסומנות. כתוצאה מכך, האקסיומות של happens before, propagates-before ו-rcu (הקובעות שאסור שיהיו מחזורים בין יחסים שונים) לא חלות על גישה רגילה. עם זאת, אנחנו כן רוצים למנוע מחזורים כאלה, משום שהם לא הגיוניים גם עבור גישה פשוטה.

לשם כך, ה-LKMM מוסיף שלוש הגבלות נוספות, שנקראות יחד "אקסיומת הקוהרנטיות הפשוטה", בזכות הדמיון שלהן לכללים ששולטים בקוהרנטיות cache במודל האופרטיבי (כללים שמסדירים את בחירת ה-store במערכת הזיכרון ומוודאים את סדר ביצוע ה-load וה-store בקוהרנטיות). ההגבלות הן:

- אם `R` ו-`W` מועמדים למירוץ וניתן לקשר את `R` ל-`W` על ידי אחד מרצפי `xbstar` שהוזכרו קודם, אז אסור שיתקיים `W ->rfe R` (כלומר, ה-load לא יכולה לקרוא מ-store שהתרחשה לפניו, גם אם אחת מהן רגילה).

- אם `W` ו-`R` מועמדים למירוץ וניתן לקשר את `W` ל-`R` על ידי אחד מרצפי ה-vis שהוזכרו קודם, אז אסור שיתקיים `R ->fre W` (כלומר, אם ה-store גלוי ל-load, אז ה-load חייב לקרוא מאותה store או אחת שקוהרנטית לה).

- אם `W` ו-`W'` מועמדים למירוץ וניתן לקשר את `W` ל-`W'` על ידי אחד מרצפי ה-vis שהוזכרו קודם, אז אסור שיתקיים `W' ->co W` (כלומר, אם store אחת גלויה לשנייה, אז השנייה חייבת להתבצע אחרי הראשונה בסדר הקוהרנטיות).




## Locking
-complete/redo



https://github.com/torvalds/linux/blob/master/tools/memory-model/Documentation/recipes.txt


הנעילה היא פשוטה וברורה, לפחות אם לא מתעמקים בה יותר מדי. הכלל הבסיסי הוא די פשוט: כל מעבד שרכש נעילה עבור מנעול מסוים, רואה את **כל השינויים** שנעשו או נראו על ידי מעבד אחר לפני שהוא שיחרר את אותו מנעול.

שים לב שזו הצהרה חזקה יותר מ-"כל מעבד המחזיק מנעול מסוים רואה את כל השינויים שנעשו על ידי מעבד אחר **בזמן שהוא מחזיק את המנעול**."

לדוגמה:

```c {linenos=inline}
/* See MP+polocks.litmus. */
void CPU0(void)
{
	WRITE_ONCE(x, 1);
	spin_lock(&mylock);
	WRITE_ONCE(y, 1);
	spin_unlock(&mylock);
}

void CPU1(void)
{
	spin_lock(&mylock);
	r0 = READ_ONCE(y);
	spin_unlock(&mylock);
	r1 = READ_ONCE(x);
}
```

הכלל הבסיסי מבטיח שאם CPU0 רוכש את המנעול `mylock` לפני CPU1, אז גם r0 וגם r1 חייבים להיות שווים ל-1. תוצאה זו מציינת שאם הערך הסופי של r0 הוא 1, אז הערך הסופי של r1 חייב להיות גם 1. לעומת זאת, הכלל החלש יותר לא אומר דבר על הערך הסופי של r1.


ההיפך של הכלל הבסיסי מתקיים גם הוא, כפי שממחיש מבחן הלקמוס הבא:

```c {linenos=inline}
/* See MP+porevlocks.litmus. */
void CPU0(void)
{
	r0 = READ_ONCE(y);
	spin_lock(&mylock);
	r1 = READ_ONCE(x);
	spin_unlock(&mylock);
}

void CPU1(void)
{
	spin_lock(&mylock);
	WRITE_ONCE(x, 1);
	spin_unlock(&mylock);
	WRITE_ONCE(y, 1);
}
```

הכלל הבסיסי במבחן הזה מצביע על כך שאם CPU0 רוכש את `mylock` לפני CPU1, אז r0 ו-r1 חייבים להיות שווים ל-0. התוצאה הנלווית לכך היא שאם הערך הסופי של r1 שווה ל-0, אז גם הערך הסופי של r0 חייב להיות 0. לעומת זאת, הכלל החלש יותר לא קובע דבר לגבי הערך הסופי של r0.

דוגמאות אלו מציגות רק זוג מעבדים אחד, אך ההשפעות של כלל הנעילה הבסיסי חלות על מספר רכישות של מנעול נתון על פני מספר מעבדים.

עם זאת, אין זה בהכרח נכון שגישה שסודרה על ידי נעילה תיראה כמסודרת על ידי מעבדים אחרים שאינם מחזיקים בנעילה זו. שקול את הדוגמה הבאה:

```c {linenos=inline}
/* See Z6.0+pooncelock+pooncelock+pombonce.litmus. */
void CPU0(void)
{
	spin_lock(&mylock);
	WRITE_ONCE(x, 1);
	WRITE_ONCE(y, 1);
	spin_unlock(&mylock);
}

void CPU1(void)
{
	spin_lock(&mylock);
	r0 = READ_ONCE(y); // 1
	WRITE_ONCE(z, 1);
	spin_unlock(&mylock);
}

void CPU2(void)
{
	WRITE_ONCE(z, 2);
	smp_mb();
	r1 = READ_ONCE(x);  // 0
}
```

למרות שזה עשוי להיות מנוגד לאינטואיציה, בהחלט אפשרי שהערך הסופי של r0 יהיה 1, הערך הסופי של z יהיה 2, והערך הסופי של r1 יהיה 0. הסיבה לתוצאה המפתיעה הזו היא ש-CPU2 מעולם לא רכש את המנעול, ולכן לא נהנה מהמנגנון שמסדר את הגישות שנעשו על ידי המעבדים שמחזיקים במנעול.


ניתן להרחיב את הסדר למעבדים שאינם מחזיקים במנעול על ידי שימוש זהיר ב-`smp_mb__after_spinlock`:


```c {linenos=inline}
/* See Z6.0+pooncelock+poonceLock+pombonce.litmus. */
void CPU0(void)
{
	spin_lock(&mylock);
	WRITE_ONCE(x, 1);
	WRITE_ONCE(y, 1);
	spin_unlock(&mylock);
}

void CPU1(void)
{
	spin_lock(&mylock);
	smp_mb__after_spinlock();
	r0 = READ_ONCE(y);
	WRITE_ONCE(z, 1);
	spin_unlock(&mylock);
}

void CPU2(void)
{
	WRITE_ONCE(z, 2);
	smp_mb();
	r1 = READ_ONCE(x);
}
```

הוספת `smp_mb__after_spinlock` מחזקת את רכישת הנעילה בצורה כזו שהיא מונעת את התוצאה המנוגדת לאינטואיציה, ומספקת סידור נכון גם עבור המעבדים שאינם מחזיקים במנעול.







לא `spin_lock` ולא `spin_unlock` חייבים לתפקד כמחסומי זיכרון מלאים. ה-LKMM בוחר שלא להחיל סידורים נוספים אלה, בעיקר כדי להימנע מהשפעה שלילית על ביצועים במקרי השימוש הפשוטים והנפוצים יותר של נעילה.

הקרנל מונע מהקומפיילר (אך לא מהמעבד) לשנות את סדר הגישות בתוך קטעים קריטיים המוגנים על ידי נעילה.

ה-`spin_lock()` ו-`spin_unlock()` לא רק שאינם מתפקדים כמחסומי זיכרון מלאים, אלא הם גם אינם מספקים את ההגנה של מחסום מלא כאשר משתמשים בהם יחד. אם נדרש לשמור על סדר בין קטעים קריטיים המשתמשים באותו מנעול, יש להבטיח זאת באופן מפורש: או שהצופה חייב להחזיק באותו מנעול, או שיש להשתמש ב-`smp_mb__after_spinlock()` או `smp_mb__after_unlock_lock()` מיד לאחר רכישת הנעילה השנייה.

הפרימיטיבי `smp_mb__after_spinlock` מבטיח סדר גישות זיכרון בכך שהוא כופה שגישות שנעשו לפני רכישת נעילה ייראו כסדרן לפני גישות שמבוצעות לאחר הקריאה ל-`smp_mb__after_spinlock`. במערכות שמסדרות באופן מלא רכישות מנעולים, זה עשוי להיות מיותר, אך במערכות אחרות הוא מספק סידור חיוני.

הפרימיטיבי `smp_mb__after_unlock_lock()` נועד לשימוש מיד לאחר רכישת נעילה, ומבטיח שכל המעבדים יראו את כל הגישות שבוצעו בקטעים קריטיים קודמים כמתרחשות לפני כל גישה שמבוצעת לאחר ה-`smp_mb__after_unlock_lock()`. הבטחה זו חלה גם על גישות בקטעים קריטיים מאוחרים יותר. "כל המעבדים" כוללים גם מעבדים שאינם מחזיקים במנעול, ו"קטעים קריטיים קודמים" כוללים הן את הקטעים הקריטיים של אותו מנעול והן את הקטעים הקריטיים של מנעולים אחרים ששוחררו על ידי אותו מעבד שביצע את `smp_mb__after_unlock_lock()`.

הפרימיטיבי `smp_mb__after_spinlock` מספק ערבויות דומות ל-`smp_mb__after_unlock_lock()`, אך בנוסף, הוא מבטיח סידור ברור יותר לגישות שבוצעו על ידי אותו מעבד שהפעיל אותו. בפרט, אם מעבד מבצע פעולת כתיבה W לפני רכישת מנעול, ואחריו מפעיל `smp_mb__after_spinlock()`, ואז מבצע פעולת קריאה R, כל המעבדים יראו את W כמתרחשת לפני R.



### נעילה במודל

משתנה מסוג `spinlock_t` מטופל כמו `int`, ו- `spin_lock(&s)` מטופל כמעט כמו:

```c {linenos=inline}
while (cmpxchg_acquire(&s, 0, 1) != 0)
	cpu_relax();
```

הקוד ממתין עד ש-`s` יהיה שווה ל-0, ואז מעדכן אותו בצורה אטומית ל-1, כאשר החלק של הקריאה בפעולת cmpxchg פועל כמחסום acquire. דרך חלופית לבטא את אותה פעולה תהיה:

```c {linenos=inline}
r = xchg_acquire(&s, 1);
```

עם דרישה שבסוף, `r = 0`. באופן דומה, `spin_trylock(&s)` מטופל **כמעט** כמו:

```c {linenos=inline}
return !cmpxchg_acquire(&s, 0, 1);
```

שבה, אם s שווה ל-0, היא מוגדרת בצורה אטומית ל-1 ומחזירה true אם הפעולה הצליחה (החלק הקריאה של cmpxchg פועל כגדר acquire רק אם הפעולה מצליחה).

הפעולה `spin_unlock(&s)` מטופלת כמעט כמו:

```c {linenos=inline}
smp_store_release(&s, 0);
```

ה"כמעט" דורש הסבר: ב-LKMM, ה-store-release ב-spin_unlock() וה-load-acquire שמהווה את החצי הראשון של עדכון ה-rmw האטומי ב-spin_lock() או spin_trylock() מוצלח - אנו יכולים לקרוא לפעולות אלו lock-releases ו-lock-acquires - יש להם שני מאפיינים נוספים מעבר לאלה של releases ו-acquires רגילים:

ראשית, כש-lock-acquire קורא מ-lock-release (יחס rf) או ש-lock-acquire הוא po אחרי lock-release, ה-LKMM דורש שכל הוראה po לפני שחרור (release) הנעילה תתבצע לפני כל הוראה שמגיעה po אחרי רכישת (acquire) הנעילה. דרישה זו מתקיימת באופן טבעי אם פעולות ה-release וה-acquire מתבצעות על מעבדים שונים וניגשות לאותו משתנה נעילה, אך ה-LKMM קובע כי היא מתקיימת גם אם הם מבוצעות על אותו מעבד, גם אם כל אחת פועלת על משתנה נעילה שונה. דוגמה לכך:

```c {linenos=inline}
int x, y;
spinlock_t s, t;

P0()
{
	int r1, r2;

	spin_lock(&s);
	r1 = READ_ONCE(x);
	spin_unlock(&s);
	spin_lock(&t);
	r2 = READ_ONCE(y);
	spin_unlock(&t);
}

P1()
{
	WRITE_ONCE(y, 1);
	smp_wmb();
	WRITE_ONCE(x, 1);
}
```

כאן, ה-spin_lock() השני הוא po אחרי ה-spin_unlock() הראשון, ולכן ה-load של x חייב להתבצע לפני ה-load של y, למרות ששתי פעולות הנעילה משתמשות במנעולים שונים. לפיכך, לא ניתן לקבל את התוצאה `r1 = 1` ו-`r2 = 0` בסוף.

דרישה זו חלה רק על פעולות release ו-acquire הקשורות למנעולים, ולא על מחסומי release ו-acquire רגילים. לדוגמה, אם היינו כותבים את P0() בצורה הבאה:

```c {linenos=inline}
P0()
{
	int r1, r2, r3;

	r1 = READ_ONCE(x);
	smp_store_release(&s, 1);
	r3 = smp_load_acquire(&s);
	r2 = READ_ONCE(y);
}
```

אז המעבד יכול להעביר את הערך `s = 1` מ-`smp_store_release` ל-`smp_load_acquire`, תוך ביצוע ההוראות בסדר הבא:

```c {linenos=inline}
r3 = smp_load_acquire(&s);	// Obtains r3 = 1
r2 = READ_ONCE(y);
r1 = READ_ONCE(x);
smp_store_release(&s, 1);	// Value is forwarded
```


כך, הוא יכול לטעון את y לפני x, ולהשיג את התוצאה `r2 = 0` ו-`r1 = 1`.

שנית, כש-lock-acquire קורא מ-lock-release (יחס rf) או ש-lock-acquire הוא po אחרי lock-release, ומספר stores אחרים, `W` ו-`W'`, מתרחשים po לפני שחרור הנעילה ו-po אחרי רכישת הנעילה בהתאמה, ה-LKMM דורש ש-`W` יתפשט לכל המעבדים לפני `W'`. לדוגמה, שקול את הקוד הבא:

```c {linenos=inline}
int x, y;
spinlock_t s;

P0()
{
	spin_lock(&s);
	WRITE_ONCE(x, 1);
	spin_unlock(&s);
}

P1()
{
	int r1;

	spin_lock(&s);
	r1 = READ_ONCE(x);
	WRITE_ONCE(y, 1);
	spin_unlock(&s);
}

P2()
{
	int r2, r3;

	r2 = READ_ONCE(y);
	smp_rmb();
	r3 = READ_ONCE(x);
}
```

אם `r1 = 1` בסוף, אז ה-spin_lock() ב-P1 חייב לקרוא מה-spin_unlock() ב-P0. מכאן שה-store ל-x חייב להתפשט ל-P2 לפני שה-store ל-y עושה זאת, כך שלא ניתן לקבל את התוצאה `r2 = 1` ו-`r3 = 0`. אך אם P1 היה משתמש במשתנה נעילה שונה מ-s, הכתיבה הייתה יכולה להתפשט בסדרים שונים. (מצד שני, אם הקוד ב-P0 ו-P1 היה רץ על אותו מעבד, כמו בדוגמה הקודמת, אז הכתיבה הייתה מתפשטת לפי הסדר גם אם היו משתמשים במנעולים שונים).

שתי הדרישות המיוחדות הללו לשחרור ורכישת נעילה אינן חלק מהמודל האופרטיבי, אך מפתחי הקרנל התחילו לצפות ולסמוך עליהן כי הן נכונות בכל הארכיטקטורות הנתמכות על ידי הקרנל, אם כי מסיבות שונות.
